{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c420c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "PROJECT_NAME = 'Car-Object-Detection-V10-Learning-Detectron2-V2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d0bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea6d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.image.AxesImage at 0x7fd834040e80>"
     ]
    }
   ],
   "source": [
    "info = data.iloc[0]\n",
    "img = cv2.imread(f'./data/{info[\"image\"]}')\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = round(xmin)\n",
    "y = round(ymin)\n",
    "w = round(xmax - xmin)\n",
    "h = round(ymax - ymin)\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),5)\n",
    "cv2.imwrite('img.png',img)\n",
    "plt.imshow(img)\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2363da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image    vid_4_1000.jpg\n",
      "xmin         281.259045\n",
      "ymin         187.035071\n",
      "xmax         327.727931\n",
      "ymax         223.225547\n",
      "Name: 0, dtype: object"
     ]
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d108799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    records = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        info = data.iloc[i]\n",
    "        record = {}\n",
    "        path = './data/' + info['image']\n",
    "        record['height'],record['width'] = cv2.imread(path).shape[:2]\n",
    "        record['file_path'] = path\n",
    "        record['image_id'] = i\n",
    "        record['annotations'] = [\n",
    "            {\n",
    "                'bbox':[info['xmin'],info['ymin'],info['xmax'],info['ymax']],\n",
    "                'bbox_mode':BoxMode.XYXY_ABS,\n",
    "                'category_id':0\n",
    "            }\n",
    "        ]\n",
    "        records.append(record)\n",
    "    np.save('./data.npy',records)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "261ee6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d246ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register('data',lambda : load_data())\n",
    "MetadataCatalog.get('data').set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f25adf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V10-Learning-Detectron2-V2/runs/26omcam2\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V10-Learning-Detectron2-V2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "model = \"\"\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "cfg.DATASETS.TRAIN = ('data')\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.MAX_ITER = 625\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "val_loader = build_detection_test_loader(cfg,'data')\n",
    "metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "wandb.log(metrics)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83969bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "model = \"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\"\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "cfg.DATASETS.TRAIN = ('data')\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.MAX_ITER = 625\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "val_loader = build_detection_test_loader(cfg,'data')\n",
    "metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "wandb.log(metrics)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
