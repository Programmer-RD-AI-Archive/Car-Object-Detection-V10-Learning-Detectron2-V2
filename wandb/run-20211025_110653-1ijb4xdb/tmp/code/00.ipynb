{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560fff0a-e37d-438b-8142-68d1118129da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "PROJECT_NAME = 'Car-Object-Detection-V10-Learning-Detectron2-V2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597fbac0-ed8c-475c-a3b3-8104edd3000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1503d8-e0a8-488c-b686-dcefb5307180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6fa068a5e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = data.iloc[0]\n",
    "img = cv2.imread(f'./data/{info[\"image\"]}')\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = round(xmin)\n",
    "y = round(ymin)\n",
    "w = round(xmax - xmin)\n",
    "h = round(ymax - ymin)\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),5)\n",
    "cv2.imwrite('img.png',img)\n",
    "plt.imshow(img)\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e962d073-00ed-4045-8ad6-a31e0d9663a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    vid_4_1000.jpg\n",
       "xmin         281.259045\n",
       "ymin         187.035071\n",
       "xmax         327.727931\n",
       "ymax         223.225547\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e67b11d-3224-4d70-ad31-e97ece42bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    records = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        info = data.iloc[i]\n",
    "        record = {}\n",
    "        path = './data/' + info['image']\n",
    "        record['height'],record['width'] = cv2.imread(path).shape[:2]\n",
    "        record['file_name'] = path\n",
    "        record['image_id'] = i\n",
    "        record['annotations'] = [\n",
    "            {\n",
    "                'bbox':[info['xmin'],info['ymin'],info['xmax'],info['ymax']],\n",
    "                'bbox_mode':BoxMode.XYXY_ABS,\n",
    "                'category_id':0\n",
    "            }\n",
    "        ]\n",
    "        records.append(record)\n",
    "    np.save('./data.npy',records)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e70c78-ab9f-4e1f-9f54-f9444344230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6e0aaa-e968-4816-b4e4-f25e6fefce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register('data',lambda : load_data())\n",
    "MetadataCatalog.get('data').set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf5133-9f33-440e-b38f-b29c16f7f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-10-25 11:06:55.213610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V10-Learning-Detectron2-V2/runs/1ijb4xdb\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V10-Learning-Detectron2-V2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 11:07:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 559/559 [00:01<00:00, 330.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 11:07:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 559 images left.\n",
      "\u001b[32m[10/25 11:07:04 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Car     | 559          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/25 11:07:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/25 11:07:04 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/25 11:07:04 d2.data.common]: \u001b[0mSerializing 559 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 11:07:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-10-25 11:07:05.290518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 11:07:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/25 11:07:12 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 19  total_loss: 1.565  loss_cls: 0.7252  loss_box_reg: 0.841  loss_rpn_cls: 0.009744  loss_rpn_loc: 0.005012  time: 0.2885  data_time: 0.0159  lr: 7.8424e-06  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:18 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 39  total_loss: 1.542  loss_cls: 0.6577  loss_box_reg: 0.8434  loss_rpn_cls: 0.006778  loss_rpn_loc: 0.006113  time: 0.2968  data_time: 0.0026  lr: 1.5834e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:24 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 59  total_loss: 1.304  loss_cls: 0.5078  loss_box_reg: 0.7654  loss_rpn_cls: 0.007434  loss_rpn_loc: 0.005585  time: 0.2977  data_time: 0.0023  lr: 2.3826e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:30 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 79  total_loss: 1.199  loss_cls: 0.3959  loss_box_reg: 0.8173  loss_rpn_cls: 0.009621  loss_rpn_loc: 0.004983  time: 0.2969  data_time: 0.0024  lr: 3.1818e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:36 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 99  total_loss: 1.081  loss_cls: 0.3062  loss_box_reg: 0.7609  loss_rpn_cls: 0.007091  loss_rpn_loc: 0.004579  time: 0.2967  data_time: 0.0027  lr: 3.981e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:42 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 119  total_loss: 1.098  loss_cls: 0.2727  loss_box_reg: 0.8106  loss_rpn_cls: 0.006731  loss_rpn_loc: 0.003671  time: 0.2978  data_time: 0.0026  lr: 4.7802e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:48 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 139  total_loss: 1.022  loss_cls: 0.2077  loss_box_reg: 0.7718  loss_rpn_cls: 0.007321  loss_rpn_loc: 0.003416  time: 0.2979  data_time: 0.0025  lr: 5.5794e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:07:54 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 159  total_loss: 1.085  loss_cls: 0.1972  loss_box_reg: 0.865  loss_rpn_cls: 0.01008  loss_rpn_loc: 0.004233  time: 0.2982  data_time: 0.0027  lr: 6.3786e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:00 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 179  total_loss: 0.9473  loss_cls: 0.1523  loss_box_reg: 0.7692  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.004546  time: 0.2985  data_time: 0.0027  lr: 7.1778e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:07 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 199  total_loss: 0.9299  loss_cls: 0.1324  loss_box_reg: 0.7894  loss_rpn_cls: 0.006521  loss_rpn_loc: 0.004563  time: 0.2997  data_time: 0.0029  lr: 7.977e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:13 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 219  total_loss: 0.7741  loss_cls: 0.1207  loss_box_reg: 0.626  loss_rpn_cls: 0.007003  loss_rpn_loc: 0.003804  time: 0.2997  data_time: 0.0026  lr: 8.7762e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:19 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 239  total_loss: 0.7846  loss_cls: 0.09379  loss_box_reg: 0.7041  loss_rpn_cls: 0.004591  loss_rpn_loc: 0.003024  time: 0.2994  data_time: 0.0025  lr: 9.5754e-05  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:25 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 259  total_loss: 0.6909  loss_cls: 0.08261  loss_box_reg: 0.5983  loss_rpn_cls: 0.004213  loss_rpn_loc: 0.003592  time: 0.3005  data_time: 0.0028  lr: 0.00010375  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:31 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 279  total_loss: 0.6433  loss_cls: 0.07529  loss_box_reg: 0.5655  loss_rpn_cls: 0.005058  loss_rpn_loc: 0.003352  time: 0.3004  data_time: 0.0025  lr: 0.00011174  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:37 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 299  total_loss: 0.6048  loss_cls: 0.06963  loss_box_reg: 0.5091  loss_rpn_cls: 0.004471  loss_rpn_loc: 0.003337  time: 0.3009  data_time: 0.0028  lr: 0.00011973  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:43 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 319  total_loss: 0.5128  loss_cls: 0.06212  loss_box_reg: 0.42  loss_rpn_cls: 0.005121  loss_rpn_loc: 0.002648  time: 0.3007  data_time: 0.0028  lr: 0.00012772  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:49 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 339  total_loss: 0.4662  loss_cls: 0.07604  loss_box_reg: 0.3848  loss_rpn_cls: 0.006239  loss_rpn_loc: 0.003217  time: 0.3002  data_time: 0.0027  lr: 0.00013571  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:08:55 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 359  total_loss: 0.4961  loss_cls: 0.06867  loss_box_reg: 0.408  loss_rpn_cls: 0.004604  loss_rpn_loc: 0.003046  time: 0.3003  data_time: 0.0027  lr: 0.00014371  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:01 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 379  total_loss: 0.4734  loss_cls: 0.06091  loss_box_reg: 0.3942  loss_rpn_cls: 0.004029  loss_rpn_loc: 0.003212  time: 0.3002  data_time: 0.0026  lr: 0.0001517  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:07 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 399  total_loss: 0.4175  loss_cls: 0.05965  loss_box_reg: 0.3481  loss_rpn_cls: 0.003975  loss_rpn_loc: 0.002563  time: 0.3004  data_time: 0.0025  lr: 0.00015969  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:13 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 419  total_loss: 0.4196  loss_cls: 0.05069  loss_box_reg: 0.3373  loss_rpn_cls: 0.00336  loss_rpn_loc: 0.003766  time: 0.3004  data_time: 0.0025  lr: 0.00016768  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:19 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 439  total_loss: 0.3793  loss_cls: 0.0597  loss_box_reg: 0.2987  loss_rpn_cls: 0.005273  loss_rpn_loc: 0.002955  time: 0.3005  data_time: 0.0036  lr: 0.00017567  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:25 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 459  total_loss: 0.3578  loss_cls: 0.0472  loss_box_reg: 0.2768  loss_rpn_cls: 0.004616  loss_rpn_loc: 0.003137  time: 0.3007  data_time: 0.0028  lr: 0.00018367  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:31 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 479  total_loss: 0.3624  loss_cls: 0.05564  loss_box_reg: 0.3004  loss_rpn_cls: 0.003569  loss_rpn_loc: 0.002522  time: 0.3008  data_time: 0.0026  lr: 0.00019166  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:37 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 499  total_loss: 0.3968  loss_cls: 0.05763  loss_box_reg: 0.353  loss_rpn_cls: 0.004064  loss_rpn_loc: 0.003166  time: 0.3007  data_time: 0.0027  lr: 0.00019965  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:43 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 519  total_loss: 0.3971  loss_cls: 0.06092  loss_box_reg: 0.3127  loss_rpn_cls: 0.003393  loss_rpn_loc: 0.0032  time: 0.3007  data_time: 0.0027  lr: 0.00020764  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:49 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 539  total_loss: 0.336  loss_cls: 0.05342  loss_box_reg: 0.2655  loss_rpn_cls: 0.004267  loss_rpn_loc: 0.002937  time: 0.3007  data_time: 0.0028  lr: 0.00021563  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:09:55 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 559  total_loss: 0.4225  loss_cls: 0.06519  loss_box_reg: 0.3413  loss_rpn_cls: 0.002567  loss_rpn_loc: 0.003315  time: 0.3006  data_time: 0.0025  lr: 0.00022363  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:10:01 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 579  total_loss: 0.3871  loss_cls: 0.03436  loss_box_reg: 0.3198  loss_rpn_cls: 0.001363  loss_rpn_loc: 0.002807  time: 0.3000  data_time: 0.0025  lr: 0.00023162  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:10:07 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 599  total_loss: 0.3863  loss_cls: 0.0517  loss_box_reg: 0.3257  loss_rpn_cls: 0.001402  loss_rpn_loc: 0.003387  time: 0.2993  data_time: 0.0026  lr: 0.00023961  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:10:12 d2.utils.events]: \u001b[0m eta: 0:00:01  iter: 619  total_loss: 0.3829  loss_cls: 0.05969  loss_box_reg: 0.3364  loss_rpn_cls: 0.005388  loss_rpn_loc: 0.002271  time: 0.2985  data_time: 0.0026  lr: 0.0002476  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:10:14 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 624  total_loss: 0.3535  loss_cls: 0.05268  loss_box_reg: 0.2844  loss_rpn_cls: 0.00462  loss_rpn_loc: 0.002271  time: 0.2984  data_time: 0.0026  lr: 0.0002496  max_mem: 1687M\n",
      "\u001b[32m[10/25 11:10:14 d2.engine.hooks]: \u001b[0mOverall training speed: 623 iterations in 0:03:05 (0.2984 s / it)\n",
      "\u001b[32m[10/25 11:10:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:06 (0:00:00 on hooks)\n",
      "\u001b[32m[10/25 11:10:14 d2.evaluation.coco_evaluation]: \u001b[0m'data' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/25 11:10:14 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'data' to COCO format ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 559/559 [00:01<00:00, 354.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 11:10:16 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 11:10:16 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 559, #annotations: 559\n",
      "\u001b[32m[10/25 11:10:16 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/data_coco_format.json' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 559/559 [00:01<00:00, 367.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 11:10:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 11:10:18 d2.data.common]: \u001b[0mSerializing 559 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 11:10:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n",
      "\u001b[32m[10/25 11:10:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 559 batches\n",
      "\u001b[32m[10/25 11:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/559. Dataloading: 0.0006 s/iter. Inference: 0.2111 s/iter. Eval: 0.0001 s/iter. Total: 0.2118 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/25 11:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 34/559. Dataloading: 0.0009 s/iter. Inference: 0.2208 s/iter. Eval: 0.0001 s/iter. Total: 0.2219 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/25 11:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 56/559. Dataloading: 0.0009 s/iter. Inference: 0.2248 s/iter. Eval: 0.0001 s/iter. Total: 0.2259 s/iter. ETA=0:01:53\n",
      "\u001b[32m[10/25 11:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 78/559. Dataloading: 0.0009 s/iter. Inference: 0.2252 s/iter. Eval: 0.0001 s/iter. Total: 0.2263 s/iter. ETA=0:01:48\n",
      "\u001b[32m[10/25 11:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 100/559. Dataloading: 0.0009 s/iter. Inference: 0.2257 s/iter. Eval: 0.0001 s/iter. Total: 0.2269 s/iter. ETA=0:01:44\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "model = \"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\"\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "cfg.DATASETS.TRAIN = ('data')\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.MAX_ITER = 625\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "val_loader = build_detection_test_loader(cfg,'data')\n",
    "metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "wandb.log(metrics)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df06e3-8fcd-4c6e-b955-9987fa42942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cfg,'cfg.pt')\n",
    "torch.save(cfg,'cfg.pth')\n",
    "torch.save(predictor,'predictor.pt')\n",
    "torch.save(predictor,'predictor.pth')\n",
    "torch.save(evaluator,'evaluator.pt')\n",
    "torch.save(evaluator,'evaluator.pth')\n",
    "torch.save(model,'model.pt')\n",
    "torch.save(model,'model.pth')\n",
    "torch.save(labels,'labels.pt')\n",
    "torch.save(labels,'labels.pth')\n",
    "torch.save(metrics,'metrics.pt')\n",
    "torch.save(metrics,'metrics.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997c7d6-1689-4355-ac40-457d95ec2228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('detectron2': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd0585e9a5027b519a27e411109b09a66bc779a1bba36bd86b08fdb64645f8a2c5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
